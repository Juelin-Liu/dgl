{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e4b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f621309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81c1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['num_redundant_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e936cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"275\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e41a1c;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#377eb8;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#4daf4a;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#984ea3;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff7f00;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.8941176470588236, 0.10196078431372549, 0.10980392156862745),\n",
       " (0.21568627450980393, 0.49411764705882355, 0.7215686274509804),\n",
       " (0.30196078431372547, 0.6862745098039216, 0.2901960784313726),\n",
       " (0.596078431372549, 0.3058823529411765, 0.6392156862745098),\n",
       " (1.0, 0.4980392156862745, 0.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array, linspace ; from numpy.random import randint\n",
    "from matplotlib.pyplot import hist, xticks, show\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "# synthesize some data \n",
    "font = {\n",
    "    'family' : 'serif',\n",
    "    'weight':'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "import seaborn as sns\n",
    "pallete = sns.color_palette(\"Set1\", 4)\n",
    "dgl_color = pallete[0]\n",
    "quiver_color = pallete[1]\n",
    "split_color = pallete[2]\n",
    "p3_color = pallete[3]\n",
    "hatches = list('-*/o')\n",
    "\n",
    "pallete = sns.color_palette(\"Set1\", 5)\n",
    "pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1797c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_name,system,sampling_sage,loading_sage,data_sage,total_sage,speed_up_sage,sampling_gat,loading_gat,data_gat,total_gat,speed_up_gat\n",
      "Orkut,DGL,4.06,60.09,9.23,73.38,x3.9,4.06,60.02,17.15,81.23,x3.2\n",
      "Orkut,Push-Pull,4.04,1.55,8.53,14.12,x0.7,4.04,1.65,37.62,43.31,x1.7\n",
      "Orkut,Quiver,6.06,4.99,8.67,19.72,x1.0,6.24,63.69,16.41,86.34,x3.4\n",
      "Orkut,dist_cache,6.10,1.36,8.63,16.09,x0.8,6.24,6.16,16.28,28.68,x1.1\n",
      "Orkut,\\name,4.32,0.09,14.62,19.03,,4.31,0.09,20.70,25.10,\n",
      "Papers100M,DGL,3.15,8.79,10.33,22.27,x1.2,2.94,8.56,30.82,42.32,x1.1\n",
      "Papers100M,Push-Pull,3.28,11.51,25.84,40.63,x2.1,3.33,11.30,65.72,80.35,x2.1\n",
      "Papers100M,Quiver,10.59,15.98,11.14,37.71,x2.0,10.04,14.96,30.49,55.49,x1.4\n",
      "Papers100M,dist_cache,10.68,7.28,11.16,29.12,x1.5,10.07,7.64,30.38,48.09,x1.3\n",
      "Papers100M,\\name,4.45,2.86,11.90,19.21,,4.66,2.40,31.23,38.29,\n",
      "Friendster,DGL,62.71,283.40,61.11,407.22,x2.3,62.56,284.76,245.94,593.26,x1.6\n",
      "Friendster,Push-Pull,85.90,350.78,151.47,588.15,x3.3,76.48,351.35,613.78,1041.61,x2.9\n",
      "Friendster,Quiver,128.89,43.46,63.56,235.91,x1.3,123.33,66.44,238.12,427.89,x1.2\n",
      "Friendster,dist_cache,127.36,45.56,62.84,235.76,x1.3,128.12,65.36,239.88,433.36,x1.2\n",
      "Friendster,\\name,72.48,5.03,100.49,178.00,,72.15,4.95,285.49,362.59,\n",
      "\n",
      "p3.8xlarge/nvlink\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "machine_name = 'p3.8xlarge/nvlink'\n",
    "# machine_name = 'g4dn.12xlarge/pcie'\n",
    "df = pd.read_csv(f'march_logs/{machine_name}_default.csv')\n",
    "# print(df)\n",
    "d = {'system': 1, 'b': 2, 'c': 3}\n",
    "dfs = []\n",
    "idx = ['model','system']\n",
    "dgl_cache_pers = [1, 0, 0, 0,]\n",
    "graphs = ['ogbn-papers100M']\n",
    "graphs = ['ogbn-papers100M','com-orkut','com-friendster']\n",
    "graphs = ['papers100M','orkut','friendster']\n",
    "graphs = ['orkut', 'papers100M', 'friendster']\n",
    "# graphs = []\n",
    "# , 'com-orkut', 'com-friendster']\n",
    "for graph_name in graphs:\n",
    "    idx.append(f'sampling_{graph_name}')\n",
    "    idx.append(f'loading_{graph_name}')\n",
    "    idx.append(f'training_{graph_name}')\n",
    "    idx.append(f'total_{graph_name}')\n",
    "batch_size = 256\n",
    "system_label = {}\n",
    "system_label = {'dgl':'DGL','p3':'Push-Pull', 'quiver':'Quiver',\\\n",
    "                    'dist_cache':'dist_cache','split':'\\\\name'}\n",
    "graph_label = {'ogbn-products':\"Products\", \"ogbn-papers100M\":\"Papers100M\", \\\n",
    "                   \"com-orkut\":\"Orkut\", \"com-friendster\":\"Friendster\"}\n",
    "graph_label = {'ogbn-products':\"Products\", \"papers100M\":\"Papers100M\", \\\n",
    "                   \"orkut\":\"Orkut\", \"friendster\":\"Friendster\"}\n",
    "dgl_time = {}\n",
    "for dataset_id,graph_name in enumerate(graphs):\n",
    "    split_time = {} \n",
    "    for i, system in enumerate(['split','dgl','p3','quiver','dist_cache','split']):\n",
    "        out = {}\n",
    "        out['graph_name'] = graph_label[graph_name]\n",
    "        out['system'] = system_label[system]\n",
    "        for model in [\"sage\", \"gat\"]:\n",
    "            dgl_cache_per = dgl_cache_pers[dataset_id]\n",
    "            dataset_df = df[(df['graph_name'] == graph_name) & (df['model'] == model)\\\n",
    "                        ]\n",
    "            \n",
    "            if system == \"dgl\":\n",
    "                row = dataset_df[dataset_df['system'].str.contains('dgl')]\n",
    "#                 print(row)\n",
    "            if system == \"dist_cache\":\n",
    "                row = dataset_df[dataset_df['system'].str.contains('dist_cache')]\n",
    "            if system == \"quiver\":\n",
    "            \n",
    "                row = dataset_df[dataset_df['system'].str.contains('quiver')]\n",
    "            if system == \"split\":\n",
    "                groot_row = dataset_df[dataset_df['system'].str.contains('split') \\\n",
    "                                       & (dataset_df['partition_type'] == 'ndst_efreq_xbal')]\n",
    "                if len(groot_row) != 1:\n",
    "                    row = groot_row[~((groot_row['cache_size'] == '0') | (groot_row['cache_size'] == '1'))]\n",
    "                else:\n",
    "                    row = groot_row\n",
    "                if(len(row) != 1):\n",
    "                    row = row[row['num_redundant_layers'] == 0]\n",
    "            if system == \"p3\":\n",
    "                row = dataset_df[dataset_df['system'].str.contains('p3')]\n",
    "            if len(row) != 1:\n",
    "                print(row, graph_name, system)\n",
    "            sampling_time = row['sampling (s)'].item()\n",
    "            if sampling_time != \"oom\":\n",
    "                n_epochs = float(row['num_epoch'].item())\n",
    "                sampling_time = float(sampling_time)\n",
    "                data_loading = float(row['feature (s)'].item())\n",
    "                training_time = (float(row['forward (s)'].item()) + float(row['backward (s)'].item()))\n",
    "                out[f'sampling_{model}'] = \"{:.2f}\".format(sampling_time)\n",
    "                out[f'loading_{model}'] = \"{:.2f}\".format(data_loading)\n",
    "                out[f'data_{model}'] = \"{:.2f}\".format(training_time)\n",
    "                training_time = sampling_time + data_loading + training_time\n",
    "                out[f'total_{model}'] = \"{:.2f}\".format(training_time)\n",
    "                if system == \"split\":\n",
    "                    split_time[model] = training_time\n",
    "                    out[f'speed_up_{model}']  = ''\n",
    "                else:\n",
    "                    out[f'speed_up_{model}'] = 'x{:.1f}'.format(training_time/split_time[model])\n",
    "                    \n",
    "            else:\n",
    "                out[f'sampling_{model}'] = \"OOM\"\n",
    "                out[f'loading_{model}'] = \"OOM\"\n",
    "                out[f'data_{model}'] = \"OOM\"\n",
    "                out[f'total_{model}'] = \"OOM\"\n",
    "                  \n",
    "        if i != 0:\n",
    "            dfs.append(pd.Series(out).to_frame().T)\n",
    "final = (pd.concat(dfs, ignore_index = True))\n",
    "print(final.to_csv(index = False))\n",
    "# print(final)\n",
    "print(machine_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
