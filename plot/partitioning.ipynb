{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e4b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e936cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"275\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e41a1c;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#377eb8;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#4daf4a;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#984ea3;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff7f00;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.8941176470588236, 0.10196078431372549, 0.10980392156862745),\n",
       " (0.21568627450980393, 0.49411764705882355, 0.7215686274509804),\n",
       " (0.30196078431372547, 0.6862745098039216, 0.2901960784313726),\n",
       " (0.596078431372549, 0.3058823529411765, 0.6392156862745098),\n",
       " (1.0, 0.4980392156862745, 0.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array, linspace ; from numpy.random import randint\n",
    "from matplotlib.pyplot import hist, xticks, show\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "# synthesize some data \n",
    "font = {\n",
    "    'family' : 'serif',\n",
    "    'weight':'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "import seaborn as sns\n",
    "pallete = sns.color_palette(\"Set1\", 4)\n",
    "dgl_color = pallete[0]\n",
    "quiver_color = pallete[1]\n",
    "groot_color = pallete[2]\n",
    "p3_color = pallete[3]\n",
    "hatches = list('-*/o')\n",
    "\n",
    "pallete = sns.color_palette(\"Set1\", 5)\n",
    "pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1797c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'machine_name', 'graph_name', 'feat_width', 'world_size',\n",
      "       'num_partition', 'num_epoch', 'fanouts', 'num_redundant_layers',\n",
      "       'batch_size', 'system', 'model', 'hid_size', 'cache_size',\n",
      "       'partition_type', 'duration (s)', 'sampling (s)', 'feature (s)',\n",
      "       'forward (s)', 'backward (s)', 'allocated (MB)', 'reserved (MB)',\n",
      "       'test accuracy %', 'edges_computed', 'edge_skew', 'min_edge',\n",
      "       'max_edge', 'run_time'],\n",
      "      dtype='object')\n",
      "graph_name,partitioning,sampling_sage,loading_sage,data_sage,total_sage,sampling_gat,loading_gat,data_gat,total_gat\n",
      "Papers100M,edge-bal,6.08,0.06,8.01,14.14,6.04,0.06,19.93,26.03\n",
      "Papers100M,score+,2.17,1.44,6.29,9.90,2.34,1.25,16.34,19.93\n",
      "Orkut,edge-bal,2.54,0.67,12.48,15.70,2.53,0.67,16.68,19.87\n",
      "Orkut,score+,2.16,0.04,7.31,9.52,2.15,0.04,10.35,12.55\n",
      "Friendster,edge-bal,50.42,0.71,59.41,110.55,57.87,0.55,175.21,233.62\n",
      "Friendster,score+,36.24,2.52,50.24,89.00,36.08,2.48,142.75,181.30\n",
      "\n",
      "p3.8xlarge/nvlink\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "machine_name = 'p3.8xlarge/nvlink'\n",
    "# machine_name = 'g4dn.12xlarge/pcie'\n",
    "df1 = pd.read_csv(f'march_logs/{machine_name}_default.csv')\n",
    "df2 = pd.read_csv(f'march_logs/{machine_name}_partition.csv')\n",
    "df = pd.concat([df1,df2], axis = 0)\n",
    "\n",
    "print(df.columns)\n",
    "# print(df)\n",
    "d = {'system': 1, 'b': 2, 'c': 3}\n",
    "dfs = []\n",
    "idx = ['model','system']\n",
    "dgl_cache_pers = [1, 0, 0, 0,]\n",
    "graphs = ['ogbn-papers100M']\n",
    "graphs = ['ogbn-papers100M','com-orkut','com-friendster']\n",
    "graphs = ['papers100M','orkut','friendster']\n",
    "# graphs = ['friendster']\n",
    "# graphs = []\n",
    "# , 'com-orkut', 'com-friendster']\n",
    "for graph_name in graphs:\n",
    "    idx.append(f'sampling_{graph_name}')\n",
    "    idx.append(f'loading_{graph_name}')\n",
    "    idx.append(f'training_{graph_name}')\n",
    "    idx.append(f'total_{graph_name}')\n",
    "batch_size = 1024\n",
    "system_label = {}\n",
    "system_label = {'ndst_efreq_xbal':'score+','ndegree_euniform_bal':'edge-bal'}\n",
    "graph_label = {'ogbn-products':\"Products\", \"ogbn-papers100M\":\"Papers100M\", \\\n",
    "                   \"com-orkut\":\"Orkut\", \"com-friendster\":\"Friendster\"}\n",
    "graph_label = {'ogbn-products':\"Products\", \"papers100M\":\"Papers100M\", \\\n",
    "                   \"orkut\":\"Orkut\", \"friendster\":\"Friendster\"}\n",
    "dgl_time = {}\n",
    "for dataset_id,graph_name in enumerate(graphs):\n",
    "#     for system in ['dgl','p3','quiver','groot']:\n",
    "    for partitioning in ['ndegree_euniform_bal', 'ndst_efreq_xbal']:\n",
    "#         print(dataset_id, graph_name, system)\n",
    "        out = {}\n",
    "        out['graph_name'] = graph_label[graph_name]\n",
    "        out['partitioning'] = system_label[partitioning]\n",
    "        for model in [\"sage\", \"gat\"]:\n",
    "            dgl_cache_per = dgl_cache_pers[dataset_id]\n",
    "            dataset_df = df[(df['graph_name'] == graph_name) & (df['model'] == model)\\\n",
    "                        & (df['batch_size'] == batch_size) & \\\n",
    "                            (df['system'].str.contains('split') & (df['partition_type'] == partitioning))\\\n",
    "                           ]\n",
    "            row = dataset_df\n",
    "            if len(row) != 1:\n",
    "                print(row)\n",
    "            sampling_time = row['sampling (s)'].item()\n",
    "            if sampling_time != \"oom\":\n",
    "                n_epochs = float(row['num_epoch'].item())\n",
    "                sampling_time = float(sampling_time)/n_epochs\n",
    "                data_loading = float(row['feature (s)'].item())/n_epochs\n",
    "                training_time = (float(row['forward (s)'].item()) + float(row['backward (s)'].item()))/n_epochs\n",
    "                out[f'sampling_{model}'] = \"{:.2f}\".format(sampling_time)\n",
    "                out[f'loading_{model}'] = \"{:.2f}\".format(data_loading)\n",
    "                out[f'data_{model}'] = \"{:.2f}\".format(training_time)\n",
    "                training_time = sampling_time + data_loading + training_time\n",
    "                out[f'total_{model}'] = \"{:.2f}\".format(training_time)\n",
    "                \n",
    "            else:\n",
    "                out[f'sampling_{model}'] = \"OOM\"\n",
    "                out[f'loading_{model}'] = \"OOM\"\n",
    "                out[f'data_{model}'] = \"OOM\"\n",
    "                out[f'total_{model}'] = \"OOM\"\n",
    "                  \n",
    "        dfs.append(pd.Series(out).to_frame().T)\n",
    "final = (pd.concat(dfs, ignore_index = True))\n",
    "print(final.to_csv(index = False))\n",
    "# print(final)\n",
    "print(machine_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
